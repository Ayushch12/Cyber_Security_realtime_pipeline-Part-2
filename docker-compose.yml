# version: "3.8"

services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    ports:
      - "2181:2181"

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - xpack.security.enrollment.enabled=false
      - xpack.security.http.ssl.enabled=false
      - xpack.security.transport.ssl.enabled=false
      - ES_JAVA_OPTS=-Xms512m -Xmx512m
    ports:
      - "9200:9200"
    volumes:
      - es-data:/usr/share/elasticsearch/data
  # grafana:
  #   image: grafana/grafana:10.2.0
  #   ports:
  #     - "3000:3000"
  #   depends_on:
  #     - elasticsearch
  #   volumes:
  #     - grafana-data:/var/lib/grafana
  #     # - grafana-storage:/var/lib/grafana

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.1
    ports:
    - "5601:5601"
    environment:
    - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    depends_on:
    - elasticsearch

  consumer:
    build: .
    command: python -m consumer.consumer
    depends_on:
      - kafka
      - elasticsearch
    environment:
    - .env
    restart: on-failure

  replay:
    build: .
    command: python -m replay.replay_ids_log
    depends_on:
      - kafka
    environment:
    - .env
    volumes:
      - ./sample_logs:/app/sample_logs
    restart: on-failure

volumes:
    es-data:
    # grafana-data:







